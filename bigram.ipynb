{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aa7cac1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rodando em: cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "# Isso vai detectar automaticamente a GPU AMD (via ROCm) ou NVIDIA (via CUDA)\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f\"Rodando em: {device}\")\n",
    "block_size = 8\n",
    "batch_size = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ba24a747",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comando para ler o conteúdo de um arquivo de texto\n",
    "with open('wizard_of_oz.txt', 'r', encoding='utf-8') as file:\n",
    "    text = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00d32aba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\\n', ' ', '!', '\"', '&', \"'\", '(', ')', '*', ',', '-', '.', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', ';', '?', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', '[', ']', '_', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '\\ufeff']\n"
     ]
    }
   ],
   "source": [
    "# Extrai todos os caracteres únicos do texto e os ordena\n",
    "chars = sorted(set(text))\n",
    "print(chars)\n",
    "vocabulary_size = len(chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d73e8300",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cria mapeamentos de caracteres para inteiros e vice-versa, além de funções de codificação e decodificação\n",
    "string_to_int = {ch: i for i, ch in enumerate(chars)}\n",
    "int_to_string = {i: ch for i, ch in enumerate(chars)}\n",
    "\n",
    "# Exemplo de lambda\n",
    "# def add_1(x, y):\n",
    "#   return x + y\n",
    "\n",
    "# é o mesmo que \n",
    "# add_1 = lambda x, y: x + y\n",
    "encode = lambda s: [string_to_int[c] for c in s]\n",
    "decode = lambda l: ''.join([int_to_string[i] for i in l])\n",
    "\n",
    "data = torch.tensor(encode(text), dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ce5aec4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([177221, 180706,  57824, 113599])\n",
      "inputs:\n",
      "tensor([[71, 58, 57,  1, 73, 61, 58,  1],\n",
      "        [68,  1, 66, 58, 58, 73,  1, 61],\n",
      "        [55, 71, 68, 68, 64, 72,  9,  1],\n",
      "        [73, 66, 58, 67, 73, 11,  1, 39]])\n",
      "targets:\n",
      "tensor([[58, 57,  1, 73, 61, 58,  1, 29],\n",
      "        [ 1, 66, 58, 58, 73,  1, 61, 58],\n",
      "        [71, 68, 68, 64, 72,  9,  1, 55],\n",
      "        [66, 58, 67, 73, 11,  1, 39, 67]])\n"
     ]
    }
   ],
   "source": [
    "# Basicamente o que estamos fazendo é pegando 80% do total do texto para treinar a LLM (da posição 1 até a posição n)\n",
    "n = int(0.8 * len(data))\n",
    "train_data = data[:n]\n",
    "val_data = data[n:]\n",
    "\n",
    "def get_batch(split):\n",
    "    data = train_data if split == 'train' else val_data\n",
    "    ix = torch.randint(len(data) - block_size, (batch_size,))\n",
    "    print(ix)\n",
    "    x = torch.stack([data[i:i+block_size] for i in ix])\n",
    "    y = torch.stack([data[i+1:i+block_size+1] for i in ix])\n",
    "    return x,y\n",
    "x,y = get_batch('train')\n",
    "print('inputs:')\n",
    "print(x)\n",
    "print('targets:')\n",
    "print(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50a04d0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "when input is tensor([80]) target is tensor(1)\n",
      "when input is tensor([80,  1]) target is tensor(1)\n",
      "when input is tensor([80,  1,  1]) target is tensor(28)\n",
      "when input is tensor([80,  1,  1, 28]) target is tensor(39)\n",
      "when input is tensor([80,  1,  1, 28, 39]) target is tensor(42)\n",
      "when input is tensor([80,  1,  1, 28, 39, 42]) target is tensor(39)\n",
      "when input is tensor([80,  1,  1, 28, 39, 42, 39]) target is tensor(44)\n",
      "when input is tensor([80,  1,  1, 28, 39, 42, 39, 44]) target is tensor(32)\n"
     ]
    }
   ],
   "source": [
    "class BigramLanguageModel(nn.Module):\n",
    "    def __init__(self,vocabulary_size):\n",
    "        super().__init__()\n",
    "        self.token_embedding_table = nn.Embedding(vocabulary_size, vocabulary_size)\n",
    "\n",
    "    def forward(self, index, targets):\n",
    "        logits = self.token_embedding_table(index)\n",
    "        B, T, C = logits.shape\n",
    "        logits = logits.view(B*T, C)\n",
    "        targets = targets.view(B*T)\n",
    "        loss = F.cross_entropy(logits, targets)\n",
    "\n",
    "        return logits"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
